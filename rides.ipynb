{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rides.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "p4aLypHFeRec",
        "WtjqtIWqWHby"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epogrebnyak/rides/blob/master/rides.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBp_HEEEyELa",
        "colab_type": "text"
      },
      "source": [
        "# Цели и набор гипотез"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8P2S3-hzS1B",
        "colab_type": "text"
      },
      "source": [
        "Цель - показать сходимость треков в разных условиях.\n",
        "\n",
        "Параметры на входе:\n",
        "\n",
        "- путь к каталогу с фалйами JSON\n",
        "- какие типы автомобилей смотрим (автобусы, грузовые, легковые, спецтранспорт)\n",
        "\n",
        "Алгоритмы поиска:\n",
        "\n",
        "- непрерывные дистанции\n",
        "- остановки\n",
        "\n",
        "На выходе:\n",
        "\n",
        "- список артефактов\n",
        "\n",
        "Иcпользуемые гипотезы:\n",
        "\n",
        "1. первая точка каждой зарегистрированной поездки - остановка с нулевой продолжительностью\n",
        "1. треки разбиваются по суткам\n",
        "1. \"автобусы\" - автомобили вместимостью не менее 8 человек"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4aLypHFeRec",
        "colab_type": "text"
      },
      "source": [
        "# Импорт зависимых модулей "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui-CNAIQQXod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXWopUWv-UYA",
        "colab_type": "text"
      },
      "source": [
        "# Создадим конфигурацию\n",
        "\n",
        "Для нового датасета нужно предоставить адрес ссылки. \n",
        "\n",
        "Dropbox: в обычной ссылке надо заменить адрес с `www.dropbox.com` на `dl.dropboxusercontent.com`, чтобы она стала скачиваемой напрямую."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYxm7x_x-1Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ссылка URL c данными и имя файла с данными\n",
        "RAW_DATA_URL = (\"https://dl.dropboxusercontent.com\" \n",
        "                \"/sh/hibzl6fkzukltk9/AABTFmhvDvxyQdUaBsKl4h59a/data_samples_json.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_5hf--DrG4l",
        "colab_type": "text"
      },
      "source": [
        "Как исполнять программу - все удалить или использовать ранее созданные промежуточные файлы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJhrbJ9arFq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Удалять ли все промежуточные файлы в начале запуска.\n",
        "# Oбычно False, но для глубокого перезапуска - True\n",
        "ERASE_EVERYTHING_AT_START = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtjqtIWqWHby",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Внутренние пути программы\n",
        "\n",
        "Эти параметры не нужно менять.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CrxIoq1-Rre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Каталог для данных\n",
        "DATADIR = Path(\"data\")  \n",
        "DATADIR.mkdir(parents=False, exist_ok=True)\n",
        "\n",
        "def datafile(filename):\n",
        "    return str(DATADIR / filename)\n",
        "\n",
        "class Filename:  \n",
        "    VEHICLES = datafile(\"vehicles.csv\")\n",
        "    CSV_SOURCE = datafile(\"source.csv\")  \n",
        "    RAW_JSON_FOLDER = str (DATADIR / \"jsons\")\n",
        "    RAW_ZIP_FILE = datafile(\"jsons.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC-Hk8ZNxEKZ",
        "colab_type": "text"
      },
      "source": [
        "# Загрузить сырые данные по трекам поездок"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8amozFdoyqJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Colab позволяет комбинировать код python и команды linux\n",
        "\n",
        "# Удалить все локальные файлы?\n",
        "if ERASE_EVERYTHING_AT_START:\n",
        "   !rm {Filename.RAW_ZIP_FILE}\n",
        "   !rm -rf {Filename.RAW_JSON_FOLDER}\n",
        "   !rm {Filename.VEHICLES}\n",
        "   !rm {Filename.CSV_SOURCE}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDs1kfqYwcdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Загружаем файлы, если их нет\n",
        "if not os.path.exists(Filename.RAW_ZIP_FILE):\n",
        "  !wget -O {Filename.RAW_ZIP_FILE} {RAW_DATA_URL}\n",
        "  !mkdir {Filename.RAW_JSON_FOLDER}\n",
        "  !unzip -o {Filename.RAW_ZIP_FILE}  -d {Filename.RAW_JSON_FOLDER} > /dev/null "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4VG2Whhxm6a",
        "colab_type": "code",
        "outputId": "c50180a9-4efd-4a12-acfc-6681a29b0acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "# проверим наличие файлов \n",
        "!echo Raw file count:\n",
        "!find {Filename.RAW_JSON_FOLDER} -type f | wc -l\n",
        "!echo Sample files:\n",
        "!ls {Filename.RAW_JSON_FOLDER} | head"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw file count:\n",
            "3464\n",
            "Sample files:\n",
            "01035dda-aeb4-11e9-80f2-10604ba895dc.json\n",
            "01035ddd-aeb4-11e9-80f2-10604ba895dc.json\n",
            "01035de0-aeb4-11e9-80f2-10604ba895dc.json\n",
            "01035de3-aeb4-11e9-80f2-10604ba895dc.json\n",
            "01035de6-aeb4-11e9-80f2-10604ba895dc.json\n",
            "01035de9-aeb4-11e9-80f2-10604ba895dc.json\n",
            "01ecaf60-dac1-11e9-80f2-10604ba895dc.json\n",
            "01ecaf64-dac1-11e9-80f2-10604ba895dc.json\n",
            "01ecaf67-dac1-11e9-80f2-10604ba895dc.json\n",
            "01ecaf6b-dac1-11e9-80f2-10604ba895dc.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHL5pALLXpEX",
        "colab_type": "text"
      },
      "source": [
        "# Типы автомобилей\n",
        "\n",
        "Получаем константы `VEHICLES` и `VEHICLE_TYPES`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CroaC4rX2cG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Folder:\n",
        "    \"\"\"Получение JSON файлов из каталога.\"\"\"\n",
        "\n",
        "    def __init__(self, directory_path: str):\n",
        "        \"\"\"Use *directory_path* as JSON file source.\"\"\"\n",
        "        self.directory = Path(directory_path)\n",
        "        assert self.directory.is_dir()\n",
        "\n",
        "    def filenames(self):\n",
        "        return list(self.directory.glob(\"*.json\"))\n",
        "\n",
        "    def count(self):\n",
        "        return len(self.filenames())\n",
        "\n",
        "    def yield_jsons(self):\n",
        "        for filename in self.filenames():\n",
        "            yield self.load_json(filename)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_json(filepath: str):\n",
        "        \"\"\"\"Load a JSON file content\"\"\"\n",
        "        with open(filepath, encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "\n",
        "class Ride:\n",
        "    def __init__(self, dict_):\n",
        "        self.summary = dict_[\"info\"]\n",
        "        self.points = dict_[\"data\"]\n",
        "\n",
        "    @property\n",
        "    def passengers(self):\n",
        "        return self.summary[\"car_passengers\"]\n",
        "\n",
        "    @property\n",
        "    def vehicle_type(self):\n",
        "        return self.summary[\"category\"]\n",
        "\n",
        "    @property\n",
        "    def duration(self):\n",
        "        a, b = [to_date(self.summary[key]) for key in (\"start_dt\", \"end_dt\")]\n",
        "        return round((b - a).total_seconds() / (60 * 60), 1)\n",
        "\n",
        "    def route_locations(self):\n",
        "        return [(p[2], p[1]) for p in self.points]\n",
        "\n",
        "    def route_dataframe(self):\n",
        "        df = pd.DataFrame(self.points, columns=KEYS)\n",
        "        df.time = df.time.apply(to_date)\n",
        "        return df\n",
        "\n",
        "    @property\n",
        "    def df(self):\n",
        "        df = self.route_dataframe()[\"time lat lon\".split()]\n",
        "        df[\"dist\"] = distance_deltas(df.lat, df.lon)  # km\n",
        "        df[\"time_delta\"] = df.time.diff().apply(lambda x: x.total_seconds())\n",
        "        df[\"speed\"] = (60 * 60) * (df[\"dist\"] / df[\"time_delta\"]).replace(\n",
        "            [np.inf, -np.inf], np.nan\n",
        "        )  # km/h\n",
        "        df[\"elapsed_hours\"] = (df.time - df.time[0]).apply(\n",
        "            lambda x: x.total_seconds()\n",
        "        ) / (\n",
        "            60 * 60\n",
        "        )  # hours\n",
        "        return df\n",
        "\n",
        "def get_vehicle_summary_raw(directory_path: str):\n",
        "    rides = map(Ride, Folder(directory_path).yield_jsons())\n",
        "    return pd.DataFrame([r.summary for r in rides])\n",
        "\n",
        "\n",
        "def get_vehicle_summary(directory_path: str):\n",
        "    \"\"\"\n",
        "    Use vehicles('data_samples_json').to_csv('vehicles.csv') to persist data.    \n",
        "    \"\"\"\n",
        "    df = get_vehicle_summary_raw(directory_path)\n",
        "    cols = [\"category\", \"car_passengers\", \"cat_carry_weight\"]\n",
        "    return df.groupby(\"car_id\").first()[cols].sort_values(cols)\n",
        "\n",
        "@dataclass\n",
        "class VehicleSummary:\n",
        "    directory_path: str = Filename.RAW_JSON_FOLDER\n",
        "    csv_path: str = Filename.VEHICLES\n",
        "\n",
        "    def get(self):\n",
        "        if not os.path.exists(self.csv_path):\n",
        "          self.__make__()\n",
        "        return self.__read__() \n",
        "    \n",
        "    def __make__(self): \n",
        "        cars_df = get_vehicle_summary(self.directory_path)\n",
        "        cars_df.to_csv(self.csv_path)\n",
        "\n",
        "    def __read__(self):\n",
        "        dtype = dict(car_id=str, category=str, car_passengers=int, \n",
        "                     cat_carry_weight=int)\n",
        "        return pd.read_csv(self.csv_path, dtype=dtype)\n",
        "\n",
        "def has(string):\n",
        "    return lambda s: string in s\n",
        "\n",
        "\n",
        "def vehicle_type(cars: pd.DataFrame):\n",
        "    \"\"\"Разобрать машины по типам:\n",
        "        \n",
        "        bus        \n",
        "        passenger\n",
        "        freight\n",
        "        special\n",
        "        \n",
        "    \"\"\"\n",
        "    cars[\"type\"] = \"other\"\n",
        "    # bus\n",
        "    cars.loc[cars.car_passengers >= 8, \"type\"] = \"bus\"\n",
        "    # passenger\n",
        "    a = (cars.category == \"Специальный\\\\Автобус \") & (cars.type == \"other\")\n",
        "    b = cars.category.apply(has(\"Легковой\")) & (cars.type == \"other\")\n",
        "    cars.loc[(a | b), \"type\"] = \"passenger\"\n",
        "    # freight\n",
        "    ix = cars.category.apply(has(\"Грузовой\"))\n",
        "    cars.loc[ix, \"type\"] = \"freight\"\n",
        "    # special\n",
        "    a = cars.category.apply(has(\"Специальный\")) & (cars.type == \"other\")\n",
        "    b = cars.category == \"Строительный\\\\Автокран\"\n",
        "    cars.loc[(a | b), \"type\"] = \"special\"\n",
        "    assert len(cars[cars.type == \"other\"].category.unique()) == 0\n",
        "    return cars.type\n",
        "\n",
        "\n",
        "def get_vehicle_dataframe():\n",
        "    cars_df = VehicleSummary().get()\n",
        "    cars_df[\"type\"] = vehicle_type(cars_df)\n",
        "    cars_df[\"qty\"] = 1\n",
        "    return cars_df\n",
        "\n",
        "\n",
        "VEHICLES = get_vehicle_dataframe()\n",
        "VEHICLE_TYPES = VEHICLES.type.unique().tolist()\n",
        "assert set(VEHICLE_TYPES) == set(['bus', 'freight', 'passenger', 'special'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJL5O3nfLgiC",
        "colab_type": "text"
      },
      "source": [
        "# Функции расстояний"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcFJDy8xLmwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from geopy.distance import great_circle\n",
        "\n",
        "\n",
        "class City:\n",
        "    Gvardeisk = (54 + 39 / 60, 21 + 4 / 60)  # Ориентир для центирования карты\n",
        "    Kaliningrad = (54 + 43 / 60, 20 + 30 / 60)\n",
        "\n",
        "\n",
        "def _distance(a, b):\n",
        "    # great_circle - менее точен, но быстрее чем geopy.distance.distance\n",
        "    # https://geopy.readthedocs.io/en/stable/#module-geopy.distance\n",
        "    return great_circle(a, b)\n",
        "\n",
        "def distance_km(a: tuple, b: tuple):\n",
        "    return _distance(a, b).km\n",
        "\n",
        "\n",
        "def safe_distance(lat, lon, prev_lat, prev_lon):\n",
        "    a = (lat, lon)\n",
        "    b = (prev_lat, prev_lon)\n",
        "    if a == b:\n",
        "        return 0\n",
        "    try:\n",
        "        return distance_km(a, b)\n",
        "    except ValueError:\n",
        "        return np.nan\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4KL2BV9LCeC",
        "colab_type": "text"
      },
      "source": [
        "# Функции создания датафрейма\n",
        "\n",
        "- make_raw_csv()\n",
        "- get_dataframe_from_raw_csv()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si9qdmABLBG2",
        "colab_type": "code",
        "outputId": "f58cfb53-d30b-4291-c4cb-fa60ce147377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "import os\n",
        "from dataclasses import dataclass\n",
        "from itertools import islice\n",
        "from time import time\n",
        "from functools import wraps\n",
        "from typing import Optional\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "def timing(f):\n",
        "    @wraps(f)\n",
        "    def wrap(*args, **kwargs):\n",
        "        ts = time()\n",
        "        result = f(*args, **kwargs)\n",
        "        te = time()\n",
        "        print(f\"{f.__name__}() took {te-ts:2.2f} sec\")\n",
        "        return result\n",
        "\n",
        "    return wrap\n",
        "\n",
        "\n",
        "def add_distance(rows):\n",
        "    prev_row = {\"ride\": \"\"}\n",
        "    for row in rows:\n",
        "        if row[\"ride\"] == prev_row[\"ride\"]:\n",
        "            row[\"dist\"] = safe_distance(\n",
        "                row[\"lat\"], row[\"lon\"], prev_row[\"lat\"], prev_row[\"lon\"]\n",
        "            )\n",
        "        else:\n",
        "            row[\"dist\"] = 0\n",
        "        prev_row = row\n",
        "        yield row\n",
        "\n",
        "\n",
        "class Points:\n",
        "    \"\"\"Получение точек треков из каталога.\"\"\"\n",
        "\n",
        "    columns = [\"time\", \"lon\", \"lat\", \"car\", \"ride\"]\n",
        "    dtypes = dict(time=int, lon=float, lat=float, car=str, ride=str, dist=float)\n",
        "\n",
        "    def __init__(self, directory_path: str):\n",
        "        self.directory_path = directory_path\n",
        "\n",
        "    def iterate(self):\n",
        "        for dict_ in Folder(self.directory_path).yield_jsons():\n",
        "            for p in dict_[\"data\"]:\n",
        "                car = dict_[\"info\"][\"car_id\"]\n",
        "                ride = dict_[\"info\"][\"id\"]\n",
        "                yield (p[0], p[1], p[2], car, ride)\n",
        "\n",
        "    @classmethod\n",
        "    def to_dict(cls, values):\n",
        "        return dict((k, v) for k, v in zip(cls.columns, values))\n",
        "\n",
        "    def islice(self, n: int, a: int):\n",
        "        return islice(self.iterate(), a, n)\n",
        "\n",
        "    def _get_iterator(self, n, skip):\n",
        "        if n is None:\n",
        "            return self.iterate()\n",
        "        else:\n",
        "            return self.islice(n + skip, skip)\n",
        "\n",
        "    @timing\n",
        "    def raw_dataframe(self, n=None, skip=0):\n",
        "        gen = self._get_iterator(n, skip)\n",
        "        gen = tqdm(gen, unit=\" rows\")\n",
        "        return pd.DataFrame(data=gen, columns=self.columns)\n",
        "\n",
        "    @timing\n",
        "    def dataframe_with_distances(self, n=None, skip=0):\n",
        "        gen = self._get_iterator(n, skip)\n",
        "        gen = map(self.to_dict, gen)\n",
        "        gen = add_distance(gen)\n",
        "        gen = tqdm(gen, unit=\" rows\")\n",
        "        return pd.DataFrame(gen)\n",
        "\n",
        "\n",
        "def to_date(x: int):\n",
        "    return pd.Timestamp(x, unit=\"s\")\n",
        "\n",
        "\n",
        "@timing\n",
        "def set_time(df):\n",
        "    df[\"time\"] = df.time.apply(to_date)\n",
        "\n",
        "\n",
        "@timing\n",
        "def set_date(df):\n",
        "    df[\"date\"] = df[\"time\"].apply(lambda x: x.date())\n",
        "\n",
        "\n",
        "@timing\n",
        "def set_time_delta(df):\n",
        "    df[\"time_delta\"] = df.time.diff()\n",
        "    # Первая точка любой поездки считается остановкой.\n",
        "    # Время пребывания в этой остановке равно 0.\n",
        "    if \"prev_ride\" not in df.columns:\n",
        "        df[\"prev_ride\"] = df.ride.shift(+1)\n",
        "    ix = df.ride != df.prev_ride\n",
        "    df.loc[ix, \"time_delta\"] = 0\n",
        "    assert df.time_delta.min() == 0\n",
        "    del df[\"prev_ride\"]\n",
        "    return df\n",
        "\n",
        "\n",
        "@timing\n",
        "def merge_with_car_types(df):\n",
        "    return df.merge(\n",
        "        VEHICLES[[\"car_id\", \"type\"]], left_on=\"car\", right_on=\"car_id\"\n",
        "    ).drop(columns=\"car_id\")\n",
        "\n",
        "\n",
        "@timing\n",
        "def to_canonic(raw_df):\n",
        "    # add new data\n",
        "    df = set_time_delta(raw_df)\n",
        "    df = merge_with_car_types(df)\n",
        "    # convert and decorate\n",
        "    set_time(df)\n",
        "    set_date(df)\n",
        "    return df\n",
        "\n",
        "@dataclass\n",
        "class LocalFile\n",
        "    path: str \n",
        "\n",
        "    def warn_file_exists(self):\n",
        "       print(f\"File {self.path} already exists.\")\n",
        "\n",
        "    def raise_path_invalid(self):\n",
        "       raise FileNotFoundError(f\"Provided path not valid: {self.path}\")\n",
        "\n",
        "    def touch(self):\n",
        "        try:\n",
        "            pd.read_csv(self.csvpath, nrows=10)\n",
        "        except OSError:\n",
        "            self.raise_path_invalid()\n",
        "\n",
        "@dataclass\n",
        "class RawData:\n",
        "    source_folder: str = Filename.RAW_JSON_FOLDER\n",
        "    csvpath: str = Filename.CSV_SOURCE\n",
        "    nrows: Optional[int] = None\n",
        "    skip: int = 0\n",
        "\n",
        "    def get_dataframe(self) -> pd.DataFrame:\n",
        "        p = Points(self.source_folder)\n",
        "        return p.dataframe_with_distances(self.nrows, self.skip)\n",
        "\n",
        "    def to_csv(self, force=False) -> None:\n",
        "        if not os.path.exists(self.csvpath) or force is True:\n",
        "            df = self.get_dataframe()\n",
        "            df.to_csv(self.csvpath, index=False)\n",
        "        else:\n",
        "            LocalFile(self.csvpath).warn_file_exists()\n",
        "\n",
        "    @timing\n",
        "    def from_cached_file(self) -> pd.DataFrame:\n",
        "        LocalFile(self.csvpath).touch()\n",
        "        return pd.read_csv(\n",
        "            self.csvpath, nrows=self.nrows, header=0, dtype=Points.dtypes\n",
        "        )\n",
        "\n",
        "\n",
        "def make_raw_csv(force=False):\n",
        "    \"\"\"Переписать треки из файлов JSON в CSV файл.\n",
        "    Примерное время исполнения: от 5-6 минут.\n",
        "    \"\"\"\n",
        "    RawData().to_csv(force)\n",
        "\n",
        "\n",
        "@timing\n",
        "def get_dataframe_from_jsons(\n",
        "    nrows: Optional[int] = None, \n",
        "    source_folder: str = Filename.RAW_JSON_FOLDER\n",
        "):\n",
        "    \"\"\"Получить типовой (канонический) набор данных из файлов JSON.\n",
        "    Это более медленный способ, он занимает 5-6 минут.\n",
        "    \"\"\"\n",
        "    print(\"Reading from JSON files...\")\n",
        "    raw_df = RawData(nrows=nrows, source_folder=source_folder).get_dataframe()\n",
        "    print(\"Finished reading JSON files, creating dataframe...\")\n",
        "    return to_canonic(raw_df)\n",
        "\n",
        "\n",
        "@timing\n",
        "def get_dataframe_from_raw_csv(\n",
        "    nrows: Optional[int] = None, \n",
        "    path: str = Filename.CSV_SOURCE,\n",
        "):\n",
        "    \"\"\"Получить типовой (канонический) набор данных из сохраненного \n",
        "    файла CSV. Это более быстрый способ, до 1-1.5 минуты.\n",
        "    \n",
        "    Файл должен быть подготовлен командой `make_raw_csv()`.\n",
        "    \"\"\"\n",
        "    print(\"Reading raw CSV file...\")\n",
        "    raw_df = RawData(csvpath=path, nrows=nrows).from_cached_file()\n",
        "    print(\"Finished reading raw CSV file\", path)\n",
        "    print(\"Creating dataframe...\")\n",
        "    return to_canonic(raw_df)\n",
        "\n",
        "\n",
        "def describe(df, stops_df):\n",
        "    r = len(stops_df) / len(df) * 100\n",
        "    print(\n",
        "        f\"\"\"Points considered: {len(df):>9}\n",
        "Stops: {len(stops_df):>9} ({r:.1f})%\"\"\"\n",
        "    )\n",
        "    return len(stops_df), len(df), r"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-61f29f0a6a65>\"\u001b[0;36m, line \u001b[0;32m126\u001b[0m\n\u001b[0;31m    class LocalFile\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuCtRHyVmnuh",
        "colab_type": "text"
      },
      "source": [
        "# Получить полный набор треков \n",
        "\n",
        "Создаем переменную `df_full`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJV6Pjae2ozW",
        "colab_type": "text"
      },
      "source": [
        "Переменную также можно проверить на корректную длину. Проверка убрана из кода, потому что заранее длина фрейма на новых данных неизвестна.\n",
        "\n",
        "```\n",
        "assert df_full.shape == (9065205, 9)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxvbtW74gE35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_raw_csv(force=ERASE_EVERYTHING_AT_START)\n",
        "try:\n",
        "  df_full  \n",
        "except NameError:  \n",
        "  df_full = get_dataframe_from_raw_csv()\n",
        "df_full.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_wdK2joxl6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_full.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}